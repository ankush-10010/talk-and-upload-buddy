# -*- coding: utf-8 -*-
"""Copy of Integration_IITIMentor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BUx5mIoOrJeolSdFuasIHNjZ4X_260nX
"""

!pip install faiss-cpu #While using CPu

!pip install pdf2image
!apt-get install -y poppler-utils
!apt-get install -y tesseract-ocr
!pip install pytesseract
!pip install pillow
!pip install openai
!pip install reportlab

!pip install pyngrok

import torch
import gc
gc.collect()
torch.cuda.empty_cache()

import os
import json
import re
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from difflib import get_close_matches

from PIL import Image
from pdf2image import convert_from_path
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
import pytesseract
from openai import OpenAI

import requests
from typing import Optional, List, Dict
from datetime import datetime, timedelta
import json

# Google Calendar API integration
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
GOOGLE_CALENDAR_AVAILABLE = True # Assume available after removing error handling for import

from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor

import httpx
import io

class QueryBot:
    def __init__(self,
                 json_file="/content/enchanced_first_year.json",
                 embedding_model="all-MiniLM-L6-v2",
                 groq_api_key="gsk_L6hKzvw8PWEb",
                 model_name="llama-3.1-8b-instant",
                 groq_api_url="https://api.groq.com/openai/v1/chat/completions"):

        self.JSON_FILE = json_file
        self.EMBEDDING_MODEL = embedding_model
        self.GROQ_API_KEY = groq_api_key or os.getenv("GROQ_API_KEY")
        self.MODEL_NAME = model_name
        self.GROQ_API_URL = groq_api_url

        self.chunks, self.metadata = self.load_course_chunks()
        self.index, self.model, self.embeddings = self.build_faiss_index(self.chunks)

    def load_course_chunks(self):
        with open(self.JSON_FILE, "r", encoding="utf-8") as f:
            raw_courses = json.load(f)

        chunks = []
        metadata = []

        for course in raw_courses:
            code = course.get("Course Code", "")
            title = course.get("Course Title", course.get("Title", ""))
            full_text = f"{code}\n{title}\n"

            for k, v in course.items():
                if isinstance(v, list):
                    full_text += f"\n{k}:\n" + "\n".join(
                        item if isinstance(item, str) else str(item) for item in v
                    )
                elif isinstance(v, dict):
                    full_text += f"\n{k}:\n" + json.dumps(v)
                elif isinstance(v, str):
                    full_text += f"\n{k}: {v}"

            for paragraph in full_text.split("\n\n"):
                if len(paragraph.strip()) > 50:
                    chunks.append(paragraph.strip())
                    metadata.append({"course": code, "title": title})

        return chunks, metadata

    def build_faiss_index(self, chunks):
        model = SentenceTransformer(self.EMBEDDING_MODEL)
        embeddings = model.encode(chunks, show_progress_bar=True)
        index = faiss.IndexFlatL2(len(embeddings[0]))
        index.add(np.array(embeddings))
        return index, model, embeddings

    def extract_course_code(self, query):
        match = re.search(r"\b([A-Z]{2,3}\s?\d{3}[A-Z]?)\b", query.upper())
        return match.group(1).replace(" ", "") if match else None

    def get_chunks_by_course_code(self, course_code):
        course_code_clean = course_code.upper().replace(" ", "")
        chunks_found = []
        for i, chunk in enumerate(self.chunks):
            code_in_chunk = self.metadata[i]["course"].upper().replace(" ", "")
            if course_code_clean in code_in_chunk:
                chunks_found.append((chunk, self.metadata[i]))
        return chunks_found

    def retrieve_relevant_chunks(self,query, index, model, chunks, metadata, top_k=4):
        course_code = self.extract_course_code(query)
        if course_code:
            chunks_for_course = self.get_chunks_by_course_code(course_code)
            if chunks_for_course:
                return chunks_for_course[:top_k]

        query_vec = self.model.encode([query])
        D, I = self.index.search(query_vec, top_k)
        return [(self.chunks[i], self.metadata[i]) for i in I[0]]

    async def query_llama(self,query, context_chunks):
      try:
        context = "\n\n".join(f"Chunk: {chunk}" for chunk, meta in context_chunks)
        payload = {
            "model": self.MODEL_NAME,
            "messages": [
                {"role": "system", "content": "You are a helpful academic assistant. Use the following course data to answer questions."},
                {"role": "user", "content": f"{context}\n\nQuestion: {query}"}
            ],
            "temperature": 0.2,
        }

        headers = {
            "Authorization": f"Bearer {self.GROQ_API_KEY}",
            "Content-Type": "application/json"
        }

        async with httpx.AsyncClient() as client:
                  response = await client.post(self.GROQ_API_URL, headers=headers, json=payload, timeout=20)
                  response.raise_for_status()
                  data = response.json()
                  return {
                          "text" : data["choices"][0]["message"]["content"].strip(),
                          "pdf_file" : None
                        }
      except Exception as e:
            raise Exception(f"Query failed: {str(e)}")

class QuestionPaperBot:
    def __init__(self, groq_api_key=None):
        self.api_key = groq_api_key or os.getenv("gsk_L6t7GEQKzvw8PWEb")
        self.client = OpenAI(api_key=self.api_key, base_url="https://api.groq.com/openai/v1")

    async def pdf_to_images(self, pdf_path):
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor() as pool:
            images = await loop.run_in_executor(pool, convert_from_path, pdf_path, 300)
            for i, page in enumerate(images):
                path = f"/content/Page_{i+1}.jpg"
                page.save(path, "JPEG")
                print(f"Saved: {path}")
            return len(images)

    async def extract_text(self, num):
        loop = asyncio.get_event_loop()
        async def process_image(i):
            image = Image.open(f"/content/Page_{i+1}.jpg")
            return pytesseract.image_to_string(image)
        tasks = [process_image(i) for i in range(num)]
        texts = await asyncio.gather(*tasks)
        text = "\n".join(texts)
        print("Extracted Text:\n", text)
        return text

    async def generate_ans_paper_text(self, raw_text):
        prompt = f"""You are an expert academic solution generator.

Your task is to:
1. Identify each distinct question from the following text.
2. Provide a detailed and accurate solution to each question.
3. Format your response such that each question is followed immediately by its solution.

For every question:
- Start with:
    Question <number>:
    <Full question text>

- Then give:
    Solution <number>:
    <Answer formatted as per marking scheme below>

Answer formatting rules based on marks:
- If the question is of **1 mark**, give a **single-line concise explanation**.
- If the question is of **2 or 3 marks**, give the answer in **3 distinct and clear points** (use bulleted format only).
- If the question is of **4 or more marks**, structure your answer into **5 detailed and logical bullet points**.

Please ensure that:
- Sub-parts of a question (like (a), (b), etc.) are included within the same question block.
- Explanations are clear, precise, and maintain academic tone.
- Use correct mathematical notation and formatting where applicable.
- You do not skip any questions.

Now, here is the question paper text:

{raw_text}

Give your output in the same format as the input."""
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {"role": "user", "content": prompt},
            ],
            "temperature": 0.7,
            "max_tokens": 2048
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        try:
          async with httpx.AsyncClient() as client:
                    response = await client.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=payload, timeout=20)
                    print("Groq API Raw Response:", response.status_code, response.text)
                    response.raise_for_status()
                    data = response.json()
                    return data["choices"][0]["message"]["content"].strip()
        except Exception as e:
              raise Exception(f"Query failed: {str(e)}")

        # print("Solutions:\n", result)
        # return result

    async def generate_question_paper_text(self, raw_text):
        prompt = f"""You are an expert question paper generator. Given the input question paper in a structured format, generate a new question paper that:
- Has the same structure
- Covers the same curriculum or topic
- Uses different wording and questions (same difficulty level)
- Keeps the same marks per question

Here is the input:

{raw_text}

Give your output in the same format as the input."""

        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {"role": "user", "content": prompt},
            ],
            "temperature": 0.7,
            "max_tokens": 2048
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",

        }
        try:
          async with httpx.AsyncClient() as client:
                    response = await client.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=payload, timeout=20)
                    print("Groq API Raw Response:", response.status_code, response.text)
                    response.raise_for_status()
                    data = response.json()
                    return data["choices"][0]["message"]["content"].strip()
        except Exception as e:
              raise Exception(f"Query failed: {str(e)}")

        # print("Generated Paper:\n", result)
        # return result

    def text_to_formatted_pdf(self, text, filename="generated_pdf.pdf"):

      buffer = io.BytesIO()
      c = canvas.Canvas(buffer, pagesize=A4)
      width, height = A4

      x_margin = 50
      y = height - 50
      line_height = 14
      font_size = 11

      initial_lines = text.split('\n')
      #print(lines)
      lines= self.split_lines_to_fit_page(initial_lines)

      for i, line in enumerate(lines):
          clean_line = line.strip()

          # If it's within the first 5 lines, center-align the title
          if i < 5 and clean_line:
              c.setFont("Times-Bold", 14)
              text_width = c.stringWidth(clean_line, "Times-Bold", 14)
              c.drawString((width - text_width) / 2, y, clean_line)
              y -= line_height
          elif clean_line.lower().startswith("part") or clean_line.lower().startswith("section") or clean_line.lower().startswith("instructions") or clean_line.lower().startswith("questions") :
              c.setFont("Times-Bold", 12)  # Make section headings bold
              c.drawString(x_margin, y, clean_line)
              y -= line_height
          elif clean_line == "":
              y -= line_height // 2
          else:
              c.setFont("Times-Roman", font_size)
              c.drawString(x_margin, y, clean_line)
              y -= line_height

          if y < 50:
              c.showPage()
              y = height - 50
              c.setFont("Times-Roman", font_size)

      c.save()
      buffer.seek(0)  # Rewind to the start of the buffer
      return {
         "text" : lines,
         "pdf_file" : buffer
      }
    def wrap_text(self,text, canvas_obj, font_name, font_size, max_width):
      """
      Wrap a single string into multiple lines so it fits within max_width.
      Returns a list of wrapped lines.
      """
      words = text.split()
      lines = []
      current_line = ""

      for word in words:
          test_line = f"{current_line} {word}".strip()
          if canvas_obj.stringWidth(test_line, font_name, font_size) <= max_width:
              current_line = test_line
          else:
              lines.append(current_line)
              current_line = word
      if current_line:
          lines.append(current_line)
      return lines
    def split_lines_to_fit_page(self,lines, font_name="Times-Roman", font_size=11, page_size=A4, margin=50):
      """
      Takes a list of strings (lines of text) and returns a new list
      where long lines are split so they fit on the PDF page.
      """
      dummy_canvas = canvas.Canvas("dummy.pdf")  # Only used to measure text width
      page_width, _ = page_size
      usable_width = page_width - 2 * margin

      fitted_lines = []
      for line in lines:
          if line.strip() == "":
              fitted_lines.append("")
          else:
              wrapped = self.wrap_text(line, dummy_canvas, font_name, font_size, usable_width)
              fitted_lines.extend(wrapped)

      return fitted_lines

    async def generate_question_paper(self,pdf_path):
        length=await self.pdf_to_images(pdf_path)
        print(f"PDF converted into {length} images.")
        Text=await self.extract_text(length)
        print("Extracted Text:\n", Text[:500])
        generated_text=await self.generate_question_paper_text(Text)
        print("Generated Answer Text:\n", generated_text[:500])
        return self.text_to_formatted_pdf(generated_text)

    async def generate_ans_paper(self,pdf_path):
        length= await self.pdf_to_images(pdf_path)
        print(f"PDF converted into {length} images.")
        Text=await self.extract_text(length)
        print("Extracted Text:\n", Text[:500])
        generated_text= await self.generate_ans_paper_text(Text)
        print("Generated Answer Text:\n", generated_text[:500])
        return self.text_to_formatted_pdf(generated_text)

# question_bot=QuestionPaperBot("gsk_XeRU2c5uqS")
# question_bot.generate_question_paper("/content/Eco_Paper.pdf")

# question_bot.generate_ans_paper("/content/question_paper.pdf")

#how to use
  # """we will take the prompt and pdf from the user , with the prompt we will decide what bot to choose and in this case , what functon to choose (to generate question or answer)"""
  # bot = QuestionPaperBot(groq_api_key="gsk_UZKlnGPiU2c5uqS")
  # bot.generate_question_paper(pdf_path="/content/Eco_Paper.pdf")

import os
import re
import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional

# class Scheduler:
#     def __init__(self, api_key: Optional[str] = None, model_name: str = "llama-3.1-8b-instant"):
#         self.GROQ_API_KEY = api_key or os.getenv("GROQ_API_KEY")
#         if not self.GROQ_API_KEY:
#             raise ValueError("GROQ_API_KEY not found. Please set it as an environment variable or pass it to the Scheduler constructor.")

#         self.MODEL_NAME = model_name
#         self.GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
#         self.TIME_ZONE = "Asia/Kolkata" # IST

#     def _query_groq(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> str:
#         """Internal method to query the Groq API."""
#         headers = {"Authorization": f"Bearer {self.GROQ_API_KEY}"}
#         payload = {
#             "model": self.MODEL_NAME,
#             "messages": [{"role": "user", "content": prompt}],
#             "temperature": temperature,
#             "max_tokens": max_tokens
#         }
#         try:
#             response = requests.post(self.GROQ_API_URL, headers=headers, json=payload, timeout=30)
#             response.raise_for_status()
#             return response.json()["choices"][0]["message"]["content"]
#         except requests.exceptions.RequestException as e:
#             print(f"Error querying Groq API: {e}")
#             raise

#     def classify_schedule_type(self, prompt: str) -> str:
#         """Uses LLM to classify whether the user prompt is for a daily or weekly schedule."""
#         classification_prompt = f"""
# You are a classification agent that determines whether a user wants a day schedule or a weekly schedule.

# Here are the rules:
# - If the prompt mentions today, tomorrow, or a specific date, it's a day schedule.
# - If the prompt mentions the whole week, weekdays, or a plan for the entire week, then it's a weekly schedule.
# - Be strict and choose only one: "day" or "week".

# Prompt: "{prompt.strip()}"
# Answer (respond only with "day" or "week"):
# """
#         result = self._query_groq(classification_prompt, max_tokens=10, temperature=0.2).lower()
#         return "week" if "week" in result else "day"

#     def build_schedule_prompt(self, task_description: str, schedule_type: str) -> str:
#         """
#         Builds the prompt for schedule generation based on type,
#         now including logic for the LLM to understand times for daily schedules.
#         """
#         if schedule_type == "day":
#             return f"""
# You are an expert productivity assistant. The user needs help organizing their daily tasks into a structured schedule.

# User's consolidated tasks, wake-up time, and sleep time are provided below.
# **VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
# 1.  **Identify the user's wake-up time and sleep time from the "User's Input".** Be flexible in understanding natural language (e.g., "6 pm in morning" should be 6:00 AM, "11 pm" should be 11:00 PM, "midnight" is 12:00 AM, "7" means 7:00 AM).
# 2.  If wake-up time is not clearly stated, assume 7:00 AM.
# 3.  If sleep time is not clearly stated, assume 10:00 PM.
# 4.  **Crucially, the schedule MUST start at the detected/default wake-up time and the VERY LAST activity MUST conclude EXACTLY at the detected/default sleep time.** Do not extend past the sleep time.
# 5.  **Ensure logical time progression:** Each task's end time MUST be after its start time. The next task MUST start immediately after the previous one ends.

# User's Input:
# \"\"\"
# {task_description}
# \"\"\"

# Please create a realistic day schedule that:
# 1. Incorporates all the user's tasks.
# 2. Includes appropriate breaks and buffer time.
# 3. Considers task priorities and logical ordering.
# 4. Accounts for meals and personal time.
# 5. Ensure lunch is scheduled between 12:30 PM and 2:00 PM.
# 6. Ensure dinner is scheduled between 8:00 PM and 10:00 PM.

# Format your response EXACTLY like this (use a TAB between Time and Task). Start with the header and your first time slot should be the detected/default wake-up time.
# üóì Today's Schedule
# Time\tTask
# [Detected/Default Wake-up Time] - [Next Hour Example/Calculated End Time]\tMorning routine and breakfast
# ... continue logically until [Detected/Default Sleep Time] (This last time slot MUST end at the sleep time).

# Strictly adhere to the single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule block.
# Ensure every scheduled item has a clear start and end time.
# """
#         elif schedule_type == "week":
#             return f"""
# You are an expert productivity assistant. The user needs help organizing their weekly tasks and goals into a structured 7-day schedule.

# User's Tasks, Goals, and Requirements for the week are provided below.
# **VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
# 1.  The schedule should cover 7 days, from Monday to Sunday.
# 2.  For each day, include a logical flow of activities.
# 3.  Ensure lunch is scheduled between 12:30 PM and 2:00 PM on all days.
# 4.  Ensure dinner is scheduled between 8:00 PM and 10:00 PM on all days.
# 5.  Assume typical wake-up (e.g., 8:00 AM) and sleep (e.g., 10:00 PM) times if not implied by specific tasks.

# User's Weekly Input:
# \"\"\"
# {task_description}
# \"\"\"

# Please create a realistic weekly schedule that:
# 1. Distributes ALL user's tasks and goals across the week appropriately.
# 2. Balances work, personal time, and rest.
# 3. Considers task priorities and deadlines.
# 4. Includes time for meals, breaks, and self-care.
# 5. Accounts for weekday vs weekend differences.

# Format your response EXACTLY like this (use a TAB between Time and Task):
# üìÖ This Week's Schedule

# MONDAY
# Time\tTask
# 9:00-10:00 AM\tMorning routine
# 10:00-12:00 PM\tImportant task 1
# ...

# TUESDAY
# Time\tTask
# 9:00-10:00 AM\tMorning routine
# ...

# Continue for all 7 days (Monday through Sunday).
# Strictly adhere to this single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule blocks for each day.
# Ensure every scheduled item has a clear start and end time.
# """
#         else:
#             raise ValueError("Invalid schedule_type. Must be 'day' or 'week'.")

#     def parse_and_format_schedule(self, raw_text: str, schedule_type: str) -> str:
#         """
#         Parses the raw AI text, extracts schedule blocks, and formats them consistently
#         for both daily and weekly schedules.
#         """
#         lines = raw_text.strip().splitlines()
#         formatted_output_lines = []
#         current_day = None
#         days_of_week_map = {
#             'MONDAY': 'Monday', 'TUESDAY': 'Tuesday', 'WEDNESDAY': 'Wednesday', 'THURSDAY': 'Thursday',
#             'FRIDAY': 'Friday', 'SATURDAY': 'Saturday', 'SUNDAY': 'Sunday'
#         }

#         # More flexible regex for time, but still relies on consistent separators or AM/PM
#         time_task_regex = re.compile(r"^\s*([\d:.\s‚Äì-]+(?:AM|PM)?(?:\s*[-‚Äì]\s*[\d:.\s‚Äì-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)


#         if schedule_type == "day":
#             start_parsing = False
#             for line in lines:
#                 stripped_line = line.strip()
#                 if "üóì Today's Schedule" in stripped_line:
#                     start_parsing = True
#                     formatted_output_lines.append("üóì Today's Schedule")
#                     formatted_output_lines.append("=" * 60)
#                     formatted_output_lines.append(f"{'Time'.ljust(20)} | {'Task'}")
#                     formatted_output_lines.append("-" * 60)
#                     continue

#                 if start_parsing:
#                     if 'Time' in stripped_line and 'Task' in stripped_line or not stripped_line:
#                         continue
#                     match = time_task_regex.match(stripped_line)
#                     if match:
#                         time = match.group(1).strip()
#                         task = match.group(2).strip()
#                         formatted_output_lines.append(f"{time.ljust(20)} | {task}")
#                     elif formatted_output_lines and not match and not stripped_line.startswith('...'):
#                         break

#         elif schedule_type == "week":
#             formatted_output_lines.append("üìÖ This Week's Schedule")
#             formatted_output_lines.append("=" * 80 + "\n")

#             in_schedule_block = False
#             for line in lines:
#                 stripped_line = line.strip()
#                 if not stripped_line:
#                     continue

#                 is_day_header = False
#                 for day_keyword, display_day_name in days_of_week_map.items():
#                     if day_keyword in stripped_line.upper() and ('TIME' not in stripped_line.upper() and 'TASK' not in stripped_line.upper()):
#                         if in_schedule_block:
#                             formatted_output_lines.append("\n")
#                         formatted_output_lines.append(f"üóì {display_day_name}")
#                         formatted_output_lines.append("-" * 40)
#                         current_day = display_day_name
#                         in_schedule_block = True
#                         is_day_header = True
#                         break

#                 if is_day_header:
#                     continue

#                 if in_schedule_block:
#                     if 'Time' in stripped_line and 'Task' in stripped_line:
#                         continue

#                     match = time_task_regex.match(stripped_line)
#                     if match:
#                         time = match.group(1).strip()
#                         task = match.group(2).strip()
#                         formatted_output_lines.append(f"{time.ljust(15)} | {task}")
#                     elif formatted_output_lines and not match and not stripped_line.startswith('...'):
#                         in_schedule_block = False
#         return "\n".join(formatted_output_lines)

#     def run_scheduler(self, initial_prompt: str):
#         """Main function to run the personal planner based on user input."""
#         print("üß† AI Personal Planner")
#         print("=" * 60)

#         schedule_type = self.classify_schedule_type(initial_prompt)
#         print(f"Detected Schedule Type: {schedule_type.capitalize()}")

#         task_description = initial_prompt # Default for weekly schedule

#         if schedule_type == 'day':
#             # For a daily schedule, get the detailed input including tasks and times
#             daily_input_prompt = """
# Please provide your daily tasks, wake-up time, and sleep time in one go.
# Example: 'I need to finish my report, do laundry, and call mom. I wake up at 7:30 AM and sleep by 10:00 PM.'
# Your input: """
#             consolidated_daily_input = input(daily_input_prompt).strip()
#             task_description = consolidated_daily_input # This is what the LLM will analyze for times and tasks

#             print(f"\n‚è≥ Generating your daily schedule...")
#             llm_prompt = self.build_schedule_prompt(task_description, schedule_type)
#         else: # schedule_type is 'week'
#             # For weekly schedule, prompt for consolidated tasks after classification
#             weekly_input_prompt = """
# Please provide your consolidated weekly tasks, goals, and any specific requirements in one go.
# Example: 'This week, I need to complete project proposal, prepare for client meeting on Wednesday, go to gym Mon/Wed/Fri evenings, and relax on Sunday. My general wake-up is 8 AM and sleep is 10 PM.'
# Your input: """
#             consolidated_weekly_input = input(weekly_input_prompt).strip()
#             task_description = consolidated_weekly_input

#             print(f"\n‚è≥ Generating your weekly schedule...")
#             llm_prompt = self.build_schedule_prompt(task_description, schedule_type)

#         raw_llm_result = self._query_groq(llm_prompt)

#         # --- Extracting wake/sleep times from the GENERATED SCHEDULE for display (Daily Only) ---
#         wake_up_time_display = "N/A (Weekly Schedule)"
#         sleep_time_display = "N/A (Weekly Schedule)"

#         if schedule_type == 'day':
#             schedule_lines = raw_llm_result.strip().splitlines()
#             time_task_regex_for_display = re.compile(r"^\s*([\d:.\s‚Äì-]+(?:AM|PM)?(?:\s*[-‚Äì]\s*[\d:.\s‚Äì-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)

#             parsed_times_tasks = []
#             for line in schedule_lines:
#                 match = time_task_regex_for_display.match(line.strip())
#                 if match:
#                     parsed_times_tasks.append(match.group(1).strip())

#             if parsed_times_tasks:
#                 wake_up_time_display = parsed_times_tasks[0].split('-')[0].strip()
#                 last_time_slot_raw = parsed_times_tasks[-1]
#                 sleep_time_match = re.search(r'[-‚Äì]\s*([\d:.\s‚Äì-]+(?:AM|PM)?)', last_time_slot_raw, re.IGNORECASE)
#                 if sleep_time_match:
#                     sleep_time_display = sleep_time_match.group(1).strip()
#                 else:
#                     sleep_time_display = last_time_slot_raw.split('-')[0].strip()

#         print(f"Schedule generated from approximately: {wake_up_time_display} to {sleep_time_display}")
#         # --- End of display time extraction ---
#         formatted_schedule = self.parse_and_format_schedule(raw_llm_result, schedule_type)
#         print("\n" + formatted_schedule)
import os
import re
import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional

class Scheduler:
    def __init__(self, api_key: Optional[str] = None, model_name: str = "llama-3.1-8b-instant"):
        self.GROQ_API_KEY = api_key or os.getenv("GROQ_API_KEY")
        if not self.GROQ_API_KEY:
            raise ValueError("GROQ_API_KEY not found. Please set it as an environment variable or pass it to the Scheduler constructor.")

        self.MODEL_NAME = model_name
        self.GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
        self.TIME_ZONE = "Asia/Kolkata" # IST

    async def _query_groq(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> str:
        """Internal method to query the Groq API."""
        headers = {"Authorization": f"Bearer {self.GROQ_API_KEY}"}
        payload = {
            "model": self.MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        try:
          async with httpx.AsyncClient() as client:
                    response = await client.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=payload, timeout=20)
                    print("Groq API Raw Response:", response.status_code, response.text)
                    response.raise_for_status()
                    data = response.json()
                    return data["choices"][0]["message"]["content"].strip()
        except Exception as e:
              raise Exception(f"Query failed: {str(e)}")

    async def classify_schedule_type(self, prompt: str) -> str:
        """Uses LLM to classify whether the user prompt is for a daily or weekly schedule."""
        classification_prompt = f"""
You are a classification agent that determines whether a user wants a day schedule or a weekly schedule.

Here are the rules:
- If the prompt mentions today, tomorrow, or a specific date, it's a day schedule.
- If the prompt mentions the whole week, weekdays, or a plan for the entire week, then it's a weekly schedule.
- Be strict and choose only one: "day" or "week".

Prompt: "{prompt.strip()}"
Answer (respond only with "day" or "week"):
"""
        result = await self._query_groq(classification_prompt, max_tokens=10, temperature=0.2)
        schedule_type = result.strip().lower()
        return "week" if "week" in result else "day"

    def build_schedule_prompt(self, task_description: str, schedule_type: str) -> str:
        """
        Builds the prompt for schedule generation based on type,
        now including logic for the LLM to understand times for daily schedules.
        """
        if schedule_type == "day":
            return f"""
You are an expert productivity assistant. The user needs help organizing their daily tasks into a structured schedule.

User's consolidated tasks, wake-up time, and sleep time are provided below.
**VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
1.  **Identify the user's wake-up time and sleep time from the "User's Input".** Be flexible in understanding natural language (e.g., "6 pm in morning" should be 6:00 AM, "11 pm" should be 11:00 PM, "midnight" is 12:00 AM, "7" means 7:00 AM).
2.  If wake-up time is not clearly stated, assume 7:00 AM.
3.  If sleep time is not clearly stated, assume 10:00 PM.
4.  **Crucially, the schedule MUST start at the detected/default wake-up time and the VERY LAST activity MUST conclude EXACTLY at the detected/default sleep time.** Do not extend past the sleep time.
5.  **Ensure logical time progression:** Each task's end time MUST be after its start time. The next task MUST start immediately after the previous one ends.

User's Input:
\"\"\"
{task_description}
\"\"\"

Please create a realistic day schedule that:
1. Incorporates all the user's tasks.
2. Includes appropriate breaks and buffer time.
3. Considers task priorities and logical ordering.
4. Accounts for meals and personal time.
5. Ensure lunch is scheduled between 12:30 PM and 2:00 PM.
6. Ensure dinner is scheduled between 8:00 PM and 10:00 PM.

Format your response EXACTLY like this (use a TAB between Time and Task). Start with the header and your first time slot should be the detected/default wake-up time.
üóì Today's Schedule
Time\tTask
[Detected/Default Wake-up Time] - [Next Hour Example/Calculated End Time]\tMorning routine and breakfast
... continue logically until [Detected/Default Sleep Time] (This last time slot MUST end at the sleep time).

Strictly adhere to the single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule block.
Ensure every scheduled item has a clear start and end time.
"""
        elif schedule_type == "week":
            return f"""
You are an expert productivity assistant. The user needs help organizing their weekly tasks and goals into a structured 7-day schedule.

User's Tasks, Goals, and Requirements for the week are provided below.
**VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
1.  The schedule should cover 7 days, from Monday to Sunday.
2.  For each day, include a logical flow of activities.
3.  Ensure lunch is scheduled between 12:30 PM and 2:00 PM on all days.
4.  Ensure dinner is scheduled between 8:00 PM and 10:00 PM on all days.
5.  Assume typical wake-up (e.g., 8:00 AM) and sleep (e.g., 10:00 PM) times if not implied by specific tasks.

User's Weekly Input:
\"\"\"
{task_description}
\"\"\"

Please create a realistic weekly schedule that:
1. Distributes ALL user's tasks and goals across the week appropriately.
2. Balances work, personal time, and rest.
3. Considers task priorities and deadlines.
4. Includes time for meals, breaks, and self-care.
5. Accounts for weekday vs weekend differences.

Format your response EXACTLY like this (use a TAB between Time and Task):
üìÖ This Week's Schedule

MONDAY
Time\tTask
9:00-10:00 AM\tMorning routine
10:00-12:00 PM\tImportant task 1
...

TUESDAY
Time\tTask
9:00-10:00 AM\tMorning routine
...

Continue for all 7 days (Monday through Sunday).
Strictly adhere to this single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule blocks for each day.
Ensure every scheduled item has a clear start and end time.
"""
        else:
            raise ValueError("Invalid schedule_type. Must be 'day' or 'week'.")

    def parse_and_format_schedule(self, raw_text: str, schedule_type: str) -> str:
        """
        Parses the raw AI text, extracts schedule blocks, and formats them consistently
        for both daily and weekly schedules.
        """
        lines = raw_text.strip().splitlines()
        formatted_output_lines = []
        current_day = None
        days_of_week_map = {
            'MONDAY': 'Monday', 'TUESDAY': 'Tuesday', 'WEDNESDAY': 'Wednesday', 'THURSDAY': 'Thursday',
            'FRIDAY': 'Friday', 'SATURDAY': 'Saturday', 'SUNDAY': 'Sunday'
        }

        # More flexible regex for time, but still relies on consistent separators or AM/PM
        time_task_regex = re.compile(r"^\s*([\d:.\s‚Äì-]+(?:AM|PM)?(?:\s*[-‚Äì]\s*[\d:.\s‚Äì-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)


        if schedule_type == "day":
            start_parsing = False
            for line in lines:
                stripped_line = line.strip()
                if "üóì Today's Schedule" in stripped_line:
                    start_parsing = True
                    formatted_output_lines.append("üóì Today's Schedule")
                    formatted_output_lines.append("=" * 60)
                    formatted_output_lines.append(f"{'Time'.ljust(20)} | {'Task'}")
                    formatted_output_lines.append("-" * 60)
                    continue

                if start_parsing:
                    if 'Time' in stripped_line and 'Task' in stripped_line or not stripped_line:
                        continue
                    match = time_task_regex.match(stripped_line)
                    if match:
                        time = match.group(1).strip()
                        task = match.group(2).strip()
                        formatted_output_lines.append(f"{time.ljust(20)} | {task}")
                    elif formatted_output_lines and not match and not stripped_line.startswith('...'):
                        break

        elif schedule_type == "week":
            formatted_output_lines.append("üìÖ This Week's Schedule")
            formatted_output_lines.append("=" * 80 + "\n")

            in_schedule_block = False
            for line in lines:
                stripped_line = line.strip()
                if not stripped_line:
                    continue

                is_day_header = False
                for day_keyword, display_day_name in days_of_week_map.items():
                    if day_keyword in stripped_line.upper() and ('TIME' not in stripped_line.upper() and 'TASK' not in stripped_line.upper()):
                        if in_schedule_block:
                            formatted_output_lines.append("\n")
                        formatted_output_lines.append(f"üóì {display_day_name}")
                        formatted_output_lines.append("-" * 40)
                        current_day = display_day_name
                        in_schedule_block = True
                        is_day_header = True
                        break

                if is_day_header:
                    continue

                if in_schedule_block:
                    if 'Time' in stripped_line and 'Task' in stripped_line:
                        continue

                    match = time_task_regex.match(stripped_line)
                    if match:
                        time = match.group(1).strip()
                        task = match.group(2).strip()
                        formatted_output_lines.append(f"{time.ljust(15)} | {task}")
                    elif formatted_output_lines and not match and not stripped_line.startswith('...'):
                        in_schedule_block = False
        return "\n".join(formatted_output_lines)

    async def run_scheduler(self, initial_prompt: str):
        """Main function to run the personal planner based on user input."""
        print("üß† AI Personal Planner")
        print("=" * 60)
        try:
          schedule_type = await self.classify_schedule_type(initial_prompt)
          print(f"Detected Schedule Type: {schedule_type.capitalize()}")

          task_description = initial_prompt # Default for weekly schedule

          if schedule_type == 'day':
              # For a daily schedule, get the detailed input including tasks and times
              daily_input_prompt = """
                Please provide your daily tasks, wake-up time, and sleep time in one go.
                Example: 'I need to finish my report, do laundry, and call mom. I wake up at 7:30 AM and sleep by 10:00 PM.'
                Your input: """
              consolidated_daily_input = input(daily_input_prompt).strip()
              task_description = consolidated_daily_input # This is what the LLM will analyze for times and tasks

              print(f"\n‚è≥ Generating your daily schedule...")
              llm_prompt = self.build_schedule_prompt(task_description, schedule_type)
          else: # schedule_type is 'week'
              # For weekly schedule, prompt for consolidated tasks after classification
              weekly_input_prompt = """
                Please provide your consolidated weekly tasks, goals, and any specific requirements in one go.
                Example: 'This week, I need to complete project proposal, prepare for client meeting on Wednesday, go to gym Mon/Wed/Fri evenings, and relax on Sunday. My general wake-up is 8 AM and sleep is 10 PM.'
                Your input: """
              consolidated_weekly_input = input(weekly_input_prompt).strip()
              task_description = consolidated_weekly_input

              print(f"\n‚è≥ Generating your weekly schedule...")
              llm_prompt = self.build_schedule_prompt(task_description, schedule_type)

          raw_llm_result = await self._query_groq(llm_prompt)

          # --- Extracting wake/sleep times from the GENERATED SCHEDULE for display (Daily Only) ---
          wake_up_time_display = "N/A (Weekly Schedule)"
          sleep_time_display = "N/A (Weekly Schedule)"

          if schedule_type == 'day':
              schedule_lines = raw_llm_result.strip().splitlines()
              time_task_regex_for_display = re.compile(r"^\s*([\d:.\s‚Äì-]+(?:AM|PM)?(?:\s*[-‚Äì]\s*[\d:.\s‚Äì-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)

              parsed_times_tasks = []
              for line in schedule_lines:
                  match = time_task_regex_for_display.match(line.strip())
                  if match:
                      parsed_times_tasks.append(match.group(1).strip())

              if parsed_times_tasks:
                  wake_up_time_display = parsed_times_tasks[0].split('-')[0].strip()
                  last_time_slot_raw = parsed_times_tasks[-1]
                  sleep_time_match = re.search(r'[-‚Äì]\s*([\d:.\s‚Äì-]+(?:AM|PM)?)', last_time_slot_raw, re.IGNORECASE)
                  if sleep_time_match:
                      sleep_time_display = sleep_time_match.group(1).strip()
                  else:
                      sleep_time_display = last_time_slot_raw.split('-')[0].strip()

          print(f"Schedule generated from approximately: {wake_up_time_display} to {sleep_time_display}")
          # --- End of display time extraction ---

          formatted_schedule = self.parse_and_format_schedule(raw_llm_result, schedule_type)
          result = {
              "text": formatted_schedule,
              "pdf_file":None}
          return result
        except Exception as e:
            return {"error": f"Failed to generate schedule: {str(e)}"}

# scheduler_bot=Scheduler("gsk_UZDiU2c5uqS")
# scheduler_bot.main("i want to make a schedule for today , i have to go to gym for 2hours , study for 3 hours")

import re
from datetime import datetime

import os
import requests

class RouterAgent:
    def __init__(self, groq_api_key=None, model="llama-3.1-8b-instant"):
        self.api_key = groq_api_key or os.getenv("gsk_L6hGDma7xThcMjstt7GEQKzvw8PWEb")
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = model

    async def classify_prompt(self, user_prompt: str) -> str:
        """Use Groq LLM to classify the type of user query."""
        system_prompt = (
            "You are an intelligent routing assistant. Classify the user's prompt into exactly one of these categories:\n"
            "1. questionpaper - If the user wants to generate questions, solutions, or answer a paper.\n"
            "2. scheduler - If the user is asking to generate a study plan, schedule, or planner.\n"
            "3. query - If the user is asking about a specific course, topics, syllabus, or other academic details.\n"
            "Return only one of these values: questionpaper, scheduler, or query. Do not explain."
        )

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.2,
            "max_tokens": 10
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        # response = requests.post(self.api_url, headers=headers, json=payload,timeout=20)
        try:
          async with httpx.AsyncClient() as client:
              response = await client.post("https://api.groq.com/openai/v1/chat/completions",headers=headers, json=payload, timeout=20)
          response.raise_for_status()
          data =  response.json()
          classification = data["choices"][0]["message"]["content"].strip().lower()
          return classification
        except httpx.HTTPStatusError as e:
            raise Exception(f"API request failed: {str(e)}")
        except Exception as e:
            raise Exception(f"Error classifying prompt: {str(e)}")

    async def route(self, user_prompt: str ,file=None):
        query_type = await self.classify_prompt(user_prompt)

        if query_type == "questionpaper":
            print("question paper call")
            return await self.call_questionpaper_bot(user_prompt , file=file)
        elif query_type == "scheduler":
            print("scheduler bot call")
            return await self.call_scheduler_bot(user_prompt)
        elif query_type == "query":
            print("query bot call")
            return await self.call_query_bot(user_prompt)
        else:
            return "‚ùå Unable to classify the query. Please try rephrasing."

    async def classify_question_answer(self, prompt , file=None):
          GROQ_API_URL="https://api.groq.com/openai/v1/chat/completions"

          headers = {"Authorization": f"Bearer {self.api_key}"}
          classification_prompt = f"""
                  You are a classification agent that determines whether a user wants to generate answers to a question paper or to generate a similar question paper.
                  Here are the rules:

                  -If the prompt mentions solving, answering, or providing answers to questions, then it's "answer".

                  -If the prompt mentions creating, generating, or making a similar/new paper based on the input, then it's "generate".

                  -Be strict and choose only one: "answer" or "generate".

          Prompt: """
          {prompt.strip()}
          """
          Answer:
          """

          payload = {
              "model": self.model,
              "messages": [
                  {"role": "user", "content": classification_prompt}
              ],
              "temperature": 0.2,
              "max_tokens": 10
          }

          # response = requests.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=payload, timeout=20)
          # response.raise_for_status()
          try:
            async with httpx.AsyncClient() as client:
                response = await client.post(self.api_url, headers=headers, json=payload, timeout=20)
                response.raise_for_status()
                data = response.json()
                result = data["choices"][0]["message"]["content"].strip().lower()
                return "answer" if "answer" in result else "question"
          except httpx.HTTPStatusError as e:
              raise Exception(f"API request failed: {str(e)}")
          except Exception as e:
              raise Exception(f"Error classifying question type: {str(e)}")

    async def call_questionpaper_bot(self,prompt,file=None):
      try:
            print("Classifying prompt")
            question_type = await self.classify_question_answer(prompt, file)
            print("Checkpoint1")
            questionP_bot = QuestionPaperBot(groq_api_key=self.api_key)
            print("Checkpoint2")
            if question_type == "answer":
                print("Solution Generator")
                result = await questionP_bot.generate_answer_paper(file)
                print("checkpoint 3")  # Ensure this is async
            else:
                print("Paper Generator")
                try:
                  result = await questionP_bot.generate_question_paper(file)
                  print("Checkpoint 3")  # Ensure this is async
                except Exception as e:
                  print("Error in question paper generation:", str(e))
                  raise
            return result
      except Exception as e:
            return {"error": f"Failed to process question paper: {str(e)}"}
    async def call_scheduler_bot(self, prompt):
        """scheduler bot wala part me do functions hai , ek weekly basis scheduler karne wali
        aur ek daily ki schedule karne wali , so we will take the user prompt and see ki wo kiss type  ka
        schedule banana chah rha 1day or 1 week and call the fucntuons on that basis"""
        try:
            scheduler_bot = Scheduler("gsk_L6hGDt7GEQKzvw8PWEb")
            result = await scheduler_bot.run_scheduler(prompt)
            return result
        except Exception as e:
            return {"error": f"Failed to generate schedule: {str(e)}"}

    async def call_query_bot(self, prompt: str):
        try:
            print("query bot section")
            query_bot = QueryBot()  # Pass API key if needed
            chunks, metadata = query_bot.load_course_chunks()  # Assume sync for now
            index, model, _ = query_bot.build_faiss_index(chunks)  # Assume sync
            relevant_chunks = query_bot.retrieve_relevant_chunks(prompt, index, model, chunks, metadata)  # Assume sync
            print("ü§ñ Thinking...")
            answer = await query_bot.query_llama(prompt, relevant_chunks)  # Make this async if it involves I/O
            return answer
        except Exception as e:
            return {"error": f"Failed to process query: {str(e)}"}

import shutil
import tempfile
from fastapi import FastAPI, Response
import io
import json

from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
from fastapi.responses import JSONResponse, StreamingResponse

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Or set specific origins like ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

router_agent = RouterAgent("gsk_L6hGDmGEQKzvw8PWEb")
#groq api wagera ham code ke andar hi fix kardenge (init ke time i mean)
@app.post("/route")
async def route_handler(
    prompt: str = Form(...),
    file: Optional[UploadFile] = File(None)
):
    temp_file_path = None

    # Handle file upload if provided
    if file:
        # Save file to a temp location so pdf2image can use it
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp:
            shutil.copyfileobj(file.file, temp)
            temp_file_path = temp.name
        print("Saved uploaded file to:", temp_file_path)

    try:
        result = await router_agent.route(prompt, temp_file_path)
        print("Routing function is done")
        print("Result dict:", result)
    except Exception as e:
        return JSONResponse(content={"error": str(e)})

    print("checkpoint 4")
    # Clean up the file after use
    if temp_file_path and os.path.exists(temp_file_path):
        os.remove(temp_file_path)

    print("checkpoint 5")
    # result must be a dict like {"text": ..., "pdf_file": ...}
    text = result.get("text", "")
    pdf_file = result.get("pdf_file", None)
    if not text:
      print("Text is empty or None")

    print("text value:", text, "Type:", type(text), "Truthy?", bool(text))
    print("pdf_file value:", pdf_file, "Type:", type(pdf_file), "Truthy?", bool(pdf_file))

    if hasattr(pdf_file, "getbuffer"):
        print("pdf size:", len(pdf_file.getbuffer()))

    # Only PDF
    if pdf_file:
      pdf_file.seek(0)
      print("pdf file is there")
      print(pdf_file)
    if text and not pdf_file:
      print("text only")
      try:
          if isinstance(text, list):
              text_str = "\n".join(text)
          else:
              text_str = str(text)

          return JSONResponse(
              content={"text": text_str},
              media_type="application/json"
          )
      except Exception as e:
          print("Text-only Response Error:", e)
          return JSONResponse(
              content={"error": "Failed to return text-only response."},
              media_type="application/json",
              status_code=500
          )

    if pdf_file and not text:
      try:
        print("only pdf")
        return StreamingResponse(
            pdf_file,
            media_type="application/pdf",
            headers={"Content-Disposition": "attachment; filename=question_paper.pdf"}
        )
      except Exception as e:
        print("PDF Streaming Error:", e)
        return JSONResponse({"error": "Failed to stream PDF."})
    if text and pdf_file:
        print("pdf+text")
        if isinstance(text, list):
            text_str = "\n".join(text)
        else:
            text_str = str(text)

        # Convert bytes to file-like object for streaming

        pdf_file.seek(0)
        pdf_bytes = pdf_file.read()
        print("PDF byte size:", len(pdf_bytes))

        # Create multipart response
        boundary = "----Boundary"
        parts = []

        # Part 1: JSON text
        json_part = (
            f'--{boundary}\r\n'
            f'Content-Type: application/json\r\n\r\n'
            f'{json.dumps({"text": text_str})}\r\n'
        )
        parts.append(json_part.encode('utf-8'))

        # Part 2: PDF
        pdf_part = (
                    f'--{boundary}\r\n'
                    f'Content-Type: application/pdf\r\n'
                    f'Content-Disposition: attachment; filename=question_paper.pdf\r\n\r\n'
                ).encode('utf-8') + pdf_bytes

        parts.append(pdf_part)

        # End boundary
        parts.append(f'--{boundary}--\r\n'.encode('utf-8'))

        # Combine parts
        body = b''.join(parts)

        try:
            return Response(
                content=body,
                media_type=f'multipart/mixed; boundary={boundary}',
                headers={"Content-Length": str(len(body))}
            )
        except Exception as e:
            print("Multipart Response Error:", e)
            return Response(
                content=json.dumps({"error": "Failed to stream PDF and text."}),
                media_type="application/json",
                status_code=500
            )

    # Fallback
    return Response(
        content=json.dumps({
            "text": prompt if prompt else "",
            "pdf_download_url": "/generated/question_paper.pdf"
        }),
        media_type="application/json"
    )

import uvicorn
from pyngrok import ngrok
import nest_asyncio
!ngrok authtoken 2yqvjh100kUp9E9dnhvBC2DUK5B
# Allow async in Colab
nest_asyncio.apply()

# Start ngrok tunnel
public_url = ngrok.connect(8000)
print("Public URL:", public_url)

# Run FastAPI server
uvicorn.run(app, host="0.0.0.0", port=8000)

# router=RouterAgent("gsk_UZDP83qNRVOcvKlnGPiU2c5uqS")
# prompt=input("Prompt")
# file_path="/content/question_paper.pdf"
# router.route(prompt , file=file_path)

