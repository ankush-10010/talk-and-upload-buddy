# -*- coding: utf-8 -*-
"""Copy of Integration_IITIMentor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BUx5mIoOrJeolSdFuasIHNjZ4X_260nX
"""

!pip install faiss-cpu #While using CPu

!pip install pdf2image
!apt-get install -y poppler-utils
!apt-get install -y tesseract-ocr
!pip install pytesseract
!pip install pillow
!pip install openai
!pip install reportlab

!pip install pyngrok

import torch
import gc
gc.collect()
torch.cuda.empty_cache()

import os
import json
import re
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from difflib import get_close_matches

from PIL import Image
from pdf2image import convert_from_path
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
import pytesseract
from openai import OpenAI

import requests
from typing import Optional, List, Dict
from datetime import datetime, timedelta
import json

# Google Calendar API integration
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
GOOGLE_CALENDAR_AVAILABLE = True # Assume available after removing error handling for import

from datetime import datetime

import httpx
import io

class QueryBot:
    def __init__(self,
                 json_file="/content/enchanced_first_year.json",
                 embedding_model="all-MiniLM-L6-v2",
                 groq_api_key="gsk_Bhj02RbwsSMSTCFYd4K417scxudTboSkoUkfzrjn",
                 model_name="llama-3.1-8b-instant",
                 groq_api_url="https://api.groq.com/openai/v1/chat/completions"):

        self.JSON_FILE = json_file
        self.EMBEDDING_MODEL = embedding_model
        self.GROQ_API_KEY = groq_api_key or os.getenv("GROQ_API_KEY")
        self.MODEL_NAME = model_name
        self.GROQ_API_URL = groq_api_url

        self.chunks, self.metadata = self.load_course_chunks()
        self.index, self.model, self.embeddings = self.build_faiss_index(self.chunks)

    def load_course_chunks(self):
        with open(self.JSON_FILE, "r", encoding="utf-8") as f:
            raw_courses = json.load(f)

        chunks = []
        metadata = []

        for course in raw_courses:
            code = course.get("Course Code", "")
            title = course.get("Course Title", course.get("Title", ""))
            full_text = f"{code}\n{title}\n"

            for k, v in course.items():
                if isinstance(v, list):
                    full_text += f"\n{k}:\n" + "\n".join(
                        item if isinstance(item, str) else str(item) for item in v
                    )
                elif isinstance(v, dict):
                    full_text += f"\n{k}:\n" + json.dumps(v)
                elif isinstance(v, str):
                    full_text += f"\n{k}: {v}"

            for paragraph in full_text.split("\n\n"):
                if len(paragraph.strip()) > 50:
                    chunks.append(paragraph.strip())
                    metadata.append({"course": code, "title": title})

        return chunks, metadata

    def build_faiss_index(self, chunks):
        model = SentenceTransformer(self.EMBEDDING_MODEL)
        embeddings = model.encode(chunks, show_progress_bar=True)
        index = faiss.IndexFlatL2(len(embeddings[0]))
        index.add(np.array(embeddings))
        return index, model, embeddings

    def extract_course_code(self, query):
        match = re.search(r"\b([A-Z]{2,3}\s?\d{3}[A-Z]?)\b", query.upper())
        return match.group(1).replace(" ", "") if match else None

    def get_chunks_by_course_code(self, course_code):
        course_code_clean = course_code.upper().replace(" ", "")
        chunks_found = []
        for i, chunk in enumerate(self.chunks):
            code_in_chunk = self.metadata[i]["course"].upper().replace(" ", "")
            if course_code_clean in code_in_chunk:
                chunks_found.append((chunk, self.metadata[i]))
        return chunks_found

    def retrieve_relevant_chunks(self,query, index, model, chunks, metadata, top_k=4):
        course_code = self.extract_course_code(query)
        if course_code:
            chunks_for_course = self.get_chunks_by_course_code(course_code)
            if chunks_for_course:
                return chunks_for_course[:top_k]

        query_vec = self.model.encode([query])
        D, I = self.index.search(query_vec, top_k)
        return [(self.chunks[i], self.metadata[i]) for i in I[0]]

    async def query_llama(self,query, context_chunks):
      try:
        context = "\n\n".join(f"Chunk: {chunk}" for chunk, meta in context_chunks)
        payload = {
            "model": self.MODEL_NAME,
            "messages": [
                {"role": "system", "content": "You are a helpful academic assistant. Use the following course data to answer questions."},
                {"role": "user", "content": f"{context}\n\nQuestion: {query}"}
            ],
            "temperature": 0.2,
        }

        headers = {
            "Authorization": f"Bearer {self.GROQ_API_KEY}",
            "Content-Type": "application/json"
        }

        async with httpx.AsyncClient() as client:
                  response = await client.post(self.GROQ_API_URL, headers=headers, json=payload, timeout=20)
                  response.raise_for_status()
                  data = response.json()
                  # return data["choices"][0]["message"]["content"].strip()
                  return {
                          "text" : data["choices"][0]["message"]["content"].strip(),
                          "pdf_file" : None
                        }
      except Exception as e:
            raise Exception(f"Query failed: {str(e)}")

class QuestionPaperBot:
    def __init__(self, groq_api_key=None):
        self.api_key = groq_api_key or os.getenv("GROQ_API_KEY")
        self.client = OpenAI(api_key=self.api_key, base_url="https://api.groq.com/openai/v1")

    def pdf_to_images(self, pdf_path):
        images = convert_from_path(pdf_path, dpi=300)
        for i, page in enumerate(images):
            path = f"/content/Page_{i+1}.jpg"
            page.save(path, "JPEG")
            print(f"Saved: {path}")
        return len(images)

    def extract_text(self, num):
        text = ""
        for i in range(num):
            image = Image.open(f"/content/Page_{i+1}.jpg")
            image_text = pytesseract.image_to_string(image)
            text += image_text
        print("Extracted Text:\n", text)
        return text

    async def generate_ans_paper_text(self, raw_text):
        prompt = f"""You are an expert academic solution generator.

Your task is to:
1. Identify each distinct question from the following text.
2. Provide a detailed and accurate solution to each question.
3. Format your response such that each question is followed immediately by its solution.

For every question:
- Start with:
    Question <number>:
    <Full question text>

- Then give:
    Solution <number>:
    <Answer formatted as per marking scheme below>

Answer formatting rules based on marks:
- If the question is of **1 mark**, give a **single-line concise explanation**.
- If the question is of **2 or 3 marks**, give the answer in **3 distinct and clear points** (use bulleted format only).
- If the question is of **4 or more marks**, structure your answer into **5 detailed and logical bullet points**.

Please ensure that:
- Sub-parts of a question (like (a), (b), etc.) are included within the same question block.
- Explanations are clear, precise, and maintain academic tone.
- Use correct mathematical notation and formatting where applicable.
- You do not skip any questions.

Now, here is the question paper text:

{raw_text}

Give your output in the same format as the input."""
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {"role": "user", "content": prompt},
            ],
            "temperature": 0.7,
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "max_tokens": 2048
        }
        try:
          async with httpx.AsyncClient() as client:
                    response = await client.post(self.client, headers=headers, json=payload, timeout=20)
                    response.raise_for_status()
                    data = response.json()
                    return data["choices"][0]["message"]["content"].strip()
        except Exception as e:
              raise Exception(f"Query failed: {str(e)}")

        # print("Solutions:\n", result)
        # return result

    async def generate_question_paper_text(self, raw_text):
        prompt = f"""You are an expert question paper generator. Given the input question paper in a structured format, generate a new question paper that:
- Has the same structure
- Covers the same curriculum or topic
- Uses different wording and questions (same difficulty level)
- Keeps the same marks per question

Here is the input:

{raw_text}

Give your output in the same format as the input."""

        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [
                {"role": "user", "content": prompt},
            ],
            "temperature": 0.7,
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "max_tokens": 2048
        }
        try:
          async with httpx.AsyncClient() as client:
                    response = await client.post(self.client, headers=headers, json=payload, timeout=20)
                    response.raise_for_status()
                    data = response.json()
                    return data["choices"][0]["message"]["content"].strip()
        except Exception as e:
              raise Exception(f"Query failed: {str(e)}")

        # print("Generated Paper:\n", result)
        # return result

    def text_to_formatted_pdf(self, text, filename="question_paper.pdf"):

      buffer = io.BytesIO()
      c = canvas.Canvas(buffer, pagesize=A4)
      width, height = A4

      x_margin = 50
      y = height - 50
      line_height = 14
      font_size = 11

      initial_lines = text.split('\n')
      #print(lines)
      lines= self.split_lines_to_fit_page(initial_lines)

      for i, line in enumerate(lines):
          clean_line = line.strip()

          # If it's within the first 5 lines, center-align the title
          if i < 5 and clean_line:
              c.setFont("Times-Bold", 14)
              text_width = c.stringWidth(clean_line, "Times-Bold", 14)
              c.drawString((width - text_width) / 2, y, clean_line)
              y -= line_height
          elif clean_line.lower().startswith("part") or clean_line.lower().startswith("section") or clean_line.lower().startswith("instructions") or clean_line.lower().startswith("questions") :
              c.setFont("Times-Bold", 12)  # Make section headings bold
              c.drawString(x_margin, y, clean_line)
              y -= line_height
          elif clean_line == "":
              y -= line_height // 2
          else:
              c.setFont("Times-Roman", font_size)
              c.drawString(x_margin, y, clean_line)
              y -= line_height

          if y < 50:
              c.showPage()
              y = height - 50
              c.setFont("Times-Roman", font_size)

      # c.save()
      buffer.seek(0)  # Rewind to the start of the buffer
      return buffer, lines

      return {
         "text" : lines,
         "pdf_file" : buffer
      }
    def wrap_text(self,text, canvas_obj, font_name, font_size, max_width):
      """
      Wrap a single string into multiple lines so it fits within max_width.
      Returns a list of wrapped lines.
      """
      words = text.split()
      lines = []
      current_line = ""

      for word in words:
          test_line = f"{current_line} {word}".strip()
          if canvas_obj.stringWidth(test_line, font_name, font_size) <= max_width:
              current_line = test_line
          else:
              lines.append(current_line)
              current_line = word
      if current_line:
          lines.append(current_line)
      return lines
    def split_lines_to_fit_page(self,lines, font_name="Times-Roman", font_size=11, page_size=A4, margin=50):
      """
      Takes a list of strings (lines of text) and returns a new list
      where long lines are split so they fit on the PDF page.
      """
      dummy_canvas = canvas.Canvas("dummy.pdf")  # Only used to measure text width
      page_width, _ = page_size
      usable_width = page_width - 2 * margin

      fitted_lines = []
      for line in lines:
          if line.strip() == "":
              fitted_lines.append("")
          else:
              wrapped = self.wrap_text(line, dummy_canvas, font_name, font_size, usable_width)
              fitted_lines.extend(wrapped)

      return fitted_lines

    def generate_question_paper(self,pdf_path):
        length= self.pdf_to_images(pdf_path)
        Text= self.extract_text(length)
        generated_text= self.generate_question_paper_text(Text)
        self.text_to_formatted_pdf(generated_text)

    def generate_ans_paper(self,pdf_path):
        length= self.pdf_to_images(pdf_path)
        Text=self.extract_text(length)
        generated_text= self.generate_ans_paper_text(Text)
        self.text_to_formatted_pdf(generated_text)

# question_bot=QuestionPaperBot("gsk_Ur4pXeRVOcvKlnGPiU2c5uqS")
# question_bot.generate_question_paper("/content/Eco_Paper.pdf")

# question_bot.generate_ans_paper("/content/question_paper.pdf")

#how to use
  # """we will take the prompt and pdf from the user , with the prompt we will decide what bot to choose and in this case , what functon to choose (to generate question or answer)"""
  # bot = QuestionPaperBot(groq_api_key="gsk_UZDP3FYwr4pXeRVOcvKlnGPiU2c5uqS")
  # bot.generate_question_paper(pdf_path="/content/Eco_Paper.pdf")

import os
import re
import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional

# class Scheduler:
#     def __init__(self, api_key: Optional[str] = None, model_name: str = "llama-3.1-8b-instant"):
#         self.GROQ_API_KEY = api_key or os.getenv("GROQ_API_KEY")
#         if not self.GROQ_API_KEY:
#             raise ValueError("GROQ_API_KEY not found. Please set it as an environment variable or pass it to the Scheduler constructor.")

#         self.MODEL_NAME = model_name
#         self.GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
#         self.TIME_ZONE = "Asia/Kolkata" # IST

#     def _query_groq(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> str:
#         """Internal method to query the Groq API."""
#         headers = {"Authorization": f"Bearer {self.GROQ_API_KEY}"}
#         payload = {
#             "model": self.MODEL_NAME,
#             "messages": [{"role": "user", "content": prompt}],
#             "temperature": temperature,
#             "max_tokens": max_tokens
#         }
#         try:
#             response = requests.post(self.GROQ_API_URL, headers=headers, json=payload, timeout=30)
#             response.raise_for_status()
#             return response.json()["choices"][0]["message"]["content"]
#         except requests.exceptions.RequestException as e:
#             print(f"Error querying Groq API: {e}")
#             raise

#     def classify_schedule_type(self, prompt: str) -> str:
#         """Uses LLM to classify whether the user prompt is for a daily or weekly schedule."""
#         classification_prompt = f"""
# You are a classification agent that determines whether a user wants a day schedule or a weekly schedule.

# Here are the rules:
# - If the prompt mentions today, tomorrow, or a specific date, it's a day schedule.
# - If the prompt mentions the whole week, weekdays, or a plan for the entire week, then it's a weekly schedule.
# - Be strict and choose only one: "day" or "week".

# Prompt: "{prompt.strip()}"
# Answer (respond only with "day" or "week"):
# """
#         result = self._query_groq(classification_prompt, max_tokens=10, temperature=0.2).lower()
#         return "week" if "week" in result else "day"

#     def build_schedule_prompt(self, task_description: str, schedule_type: str) -> str:
#         """
#         Builds the prompt for schedule generation based on type,
#         now including logic for the LLM to understand times for daily schedules.
#         """
#         if schedule_type == "day":
#             return f"""
# You are an expert productivity assistant. The user needs help organizing their daily tasks into a structured schedule.

# User's consolidated tasks, wake-up time, and sleep time are provided below.
# **VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
# 1.  **Identify the user's wake-up time and sleep time from the "User's Input".** Be flexible in understanding natural language (e.g., "6 pm in morning" should be 6:00 AM, "11 pm" should be 11:00 PM, "midnight" is 12:00 AM, "7" means 7:00 AM).
# 2.  If wake-up time is not clearly stated, assume 7:00 AM.
# 3.  If sleep time is not clearly stated, assume 10:00 PM.
# 4.  **Crucially, the schedule MUST start at the detected/default wake-up time and the VERY LAST activity MUST conclude EXACTLY at the detected/default sleep time.** Do not extend past the sleep time.
# 5.  **Ensure logical time progression:** Each task's end time MUST be after its start time. The next task MUST start immediately after the previous one ends.

# User's Input:
# \"\"\"
# {task_description}
# \"\"\"

# Please create a realistic day schedule that:
# 1. Incorporates all the user's tasks.
# 2. Includes appropriate breaks and buffer time.
# 3. Considers task priorities and logical ordering.
# 4. Accounts for meals and personal time.
# 5. Ensure lunch is scheduled between 12:30 PM and 2:00 PM.
# 6. Ensure dinner is scheduled between 8:00 PM and 10:00 PM.

# Format your response EXACTLY like this (use a TAB between Time and Task). Start with the header and your first time slot should be the detected/default wake-up time.
# 🗓 Today's Schedule
# Time\tTask
# [Detected/Default Wake-up Time] - [Next Hour Example/Calculated End Time]\tMorning routine and breakfast
# ... continue logically until [Detected/Default Sleep Time] (This last time slot MUST end at the sleep time).

# Strictly adhere to the single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule block.
# Ensure every scheduled item has a clear start and end time.
# """
#         elif schedule_type == "week":
#             return f"""
# You are an expert productivity assistant. The user needs help organizing their weekly tasks and goals into a structured 7-day schedule.

# User's Tasks, Goals, and Requirements for the week are provided below.
# **VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
# 1.  The schedule should cover 7 days, from Monday to Sunday.
# 2.  For each day, include a logical flow of activities.
# 3.  Ensure lunch is scheduled between 12:30 PM and 2:00 PM on all days.
# 4.  Ensure dinner is scheduled between 8:00 PM and 10:00 PM on all days.
# 5.  Assume typical wake-up (e.g., 8:00 AM) and sleep (e.g., 10:00 PM) times if not implied by specific tasks.

# User's Weekly Input:
# \"\"\"
# {task_description}
# \"\"\"

# Please create a realistic weekly schedule that:
# 1. Distributes ALL user's tasks and goals across the week appropriately.
# 2. Balances work, personal time, and rest.
# 3. Considers task priorities and deadlines.
# 4. Includes time for meals, breaks, and self-care.
# 5. Accounts for weekday vs weekend differences.

# Format your response EXACTLY like this (use a TAB between Time and Task):
# 📅 This Week's Schedule

# MONDAY
# Time\tTask
# 9:00-10:00 AM\tMorning routine
# 10:00-12:00 PM\tImportant task 1
# ...

# TUESDAY
# Time\tTask
# 9:00-10:00 AM\tMorning routine
# ...

# Continue for all 7 days (Monday through Sunday).
# Strictly adhere to this single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule blocks for each day.
# Ensure every scheduled item has a clear start and end time.
# """
#         else:
#             raise ValueError("Invalid schedule_type. Must be 'day' or 'week'.")

#     def parse_and_format_schedule(self, raw_text: str, schedule_type: str) -> str:
#         """
#         Parses the raw AI text, extracts schedule blocks, and formats them consistently
#         for both daily and weekly schedules.
#         """
#         lines = raw_text.strip().splitlines()
#         formatted_output_lines = []
#         current_day = None
#         days_of_week_map = {
#             'MONDAY': 'Monday', 'TUESDAY': 'Tuesday', 'WEDNESDAY': 'Wednesday', 'THURSDAY': 'Thursday',
#             'FRIDAY': 'Friday', 'SATURDAY': 'Saturday', 'SUNDAY': 'Sunday'
#         }

#         # More flexible regex for time, but still relies on consistent separators or AM/PM
#         time_task_regex = re.compile(r"^\s*([\d:.\s–-]+(?:AM|PM)?(?:\s*[-–]\s*[\d:.\s–-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)


#         if schedule_type == "day":
#             start_parsing = False
#             for line in lines:
#                 stripped_line = line.strip()
#                 if "🗓 Today's Schedule" in stripped_line:
#                     start_parsing = True
#                     formatted_output_lines.append("🗓 Today's Schedule")
#                     formatted_output_lines.append("=" * 60)
#                     formatted_output_lines.append(f"{'Time'.ljust(20)} | {'Task'}")
#                     formatted_output_lines.append("-" * 60)
#                     continue

#                 if start_parsing:
#                     if 'Time' in stripped_line and 'Task' in stripped_line or not stripped_line:
#                         continue
#                     match = time_task_regex.match(stripped_line)
#                     if match:
#                         time = match.group(1).strip()
#                         task = match.group(2).strip()
#                         formatted_output_lines.append(f"{time.ljust(20)} | {task}")
#                     elif formatted_output_lines and not match and not stripped_line.startswith('...'):
#                         break

#         elif schedule_type == "week":
#             formatted_output_lines.append("📅 This Week's Schedule")
#             formatted_output_lines.append("=" * 80 + "\n")

#             in_schedule_block = False
#             for line in lines:
#                 stripped_line = line.strip()
#                 if not stripped_line:
#                     continue

#                 is_day_header = False
#                 for day_keyword, display_day_name in days_of_week_map.items():
#                     if day_keyword in stripped_line.upper() and ('TIME' not in stripped_line.upper() and 'TASK' not in stripped_line.upper()):
#                         if in_schedule_block:
#                             formatted_output_lines.append("\n")
#                         formatted_output_lines.append(f"🗓 {display_day_name}")
#                         formatted_output_lines.append("-" * 40)
#                         current_day = display_day_name
#                         in_schedule_block = True
#                         is_day_header = True
#                         break

#                 if is_day_header:
#                     continue

#                 if in_schedule_block:
#                     if 'Time' in stripped_line and 'Task' in stripped_line:
#                         continue

#                     match = time_task_regex.match(stripped_line)
#                     if match:
#                         time = match.group(1).strip()
#                         task = match.group(2).strip()
#                         formatted_output_lines.append(f"{time.ljust(15)} | {task}")
#                     elif formatted_output_lines and not match and not stripped_line.startswith('...'):
#                         in_schedule_block = False
#         return "\n".join(formatted_output_lines)

#     def run_scheduler(self, initial_prompt: str):
#         """Main function to run the personal planner based on user input."""
#         print("🧠 AI Personal Planner")
#         print("=" * 60)

#         schedule_type = self.classify_schedule_type(initial_prompt)
#         print(f"Detected Schedule Type: {schedule_type.capitalize()}")

#         task_description = initial_prompt # Default for weekly schedule

#         if schedule_type == 'day':
#             # For a daily schedule, get the detailed input including tasks and times
#             daily_input_prompt = """
# Please provide your daily tasks, wake-up time, and sleep time in one go.
# Example: 'I need to finish my report, do laundry, and call mom. I wake up at 7:30 AM and sleep by 10:00 PM.'
# Your input: """
#             consolidated_daily_input = input(daily_input_prompt).strip()
#             task_description = consolidated_daily_input # This is what the LLM will analyze for times and tasks

#             print(f"\n⏳ Generating your daily schedule...")
#             llm_prompt = self.build_schedule_prompt(task_description, schedule_type)
#         else: # schedule_type is 'week'
#             # For weekly schedule, prompt for consolidated tasks after classification
#             weekly_input_prompt = """
# Please provide your consolidated weekly tasks, goals, and any specific requirements in one go.
# Example: 'This week, I need to complete project proposal, prepare for client meeting on Wednesday, go to gym Mon/Wed/Fri evenings, and relax on Sunday. My general wake-up is 8 AM and sleep is 10 PM.'
# Your input: """
#             consolidated_weekly_input = input(weekly_input_prompt).strip()
#             task_description = consolidated_weekly_input

#             print(f"\n⏳ Generating your weekly schedule...")
#             llm_prompt = self.build_schedule_prompt(task_description, schedule_type)

#         raw_llm_result = self._query_groq(llm_prompt)

#         # --- Extracting wake/sleep times from the GENERATED SCHEDULE for display (Daily Only) ---
#         wake_up_time_display = "N/A (Weekly Schedule)"
#         sleep_time_display = "N/A (Weekly Schedule)"

#         if schedule_type == 'day':
#             schedule_lines = raw_llm_result.strip().splitlines()
#             time_task_regex_for_display = re.compile(r"^\s*([\d:.\s–-]+(?:AM|PM)?(?:\s*[-–]\s*[\d:.\s–-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)

#             parsed_times_tasks = []
#             for line in schedule_lines:
#                 match = time_task_regex_for_display.match(line.strip())
#                 if match:
#                     parsed_times_tasks.append(match.group(1).strip())

#             if parsed_times_tasks:
#                 wake_up_time_display = parsed_times_tasks[0].split('-')[0].strip()
#                 last_time_slot_raw = parsed_times_tasks[-1]
#                 sleep_time_match = re.search(r'[-–]\s*([\d:.\s–-]+(?:AM|PM)?)', last_time_slot_raw, re.IGNORECASE)
#                 if sleep_time_match:
#                     sleep_time_display = sleep_time_match.group(1).strip()
#                 else:
#                     sleep_time_display = last_time_slot_raw.split('-')[0].strip()

#         print(f"Schedule generated from approximately: {wake_up_time_display} to {sleep_time_display}")
#         # --- End of display time extraction ---
#         formatted_schedule = self.parse_and_format_schedule(raw_llm_result, schedule_type)
#         print("\n" + formatted_schedule)
import os
import re
import requests
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional

class Scheduler:
    def __init__(self, api_key: Optional[str] = None, model_name: str = "llama-3.1-8b-instant"):
        self.GROQ_API_KEY = api_key or os.getenv("GROQ_API_KEY")
        if not self.GROQ_API_KEY:
            raise ValueError("GROQ_API_KEY not found. Please set it as an environment variable or pass it to the Scheduler constructor.")

        self.MODEL_NAME = model_name
        self.GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
        self.TIME_ZONE = "Asia/Kolkata" # IST

    def _query_groq(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7) -> str:
        """Internal method to query the Groq API."""
        headers = {"Authorization": f"Bearer {self.GROQ_API_KEY}"}
        payload = {
            "model": self.MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        try:
            response = requests.post(self.GROQ_API_URL, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]
        except requests.exceptions.RequestException as e:
            print(f"Error querying Groq API: {e}")
            raise

    def classify_schedule_type(self, prompt: str) -> str:
        """Uses LLM to classify whether the user prompt is for a daily or weekly schedule."""
        classification_prompt = f"""
You are a classification agent that determines whether a user wants a day schedule or a weekly schedule.

Here are the rules:
- If the prompt mentions today, tomorrow, or a specific date, it's a day schedule.
- If the prompt mentions the whole week, weekdays, or a plan for the entire week, then it's a weekly schedule.
- Be strict and choose only one: "day" or "week".

Prompt: "{prompt.strip()}"
Answer (respond only with "day" or "week"):
"""
        result = self._query_groq(classification_prompt, max_tokens=10, temperature=0.2).lower()
        return "week" if "week" in result else "day"

    def build_schedule_prompt(self, task_description: str, schedule_type: str) -> str:
        """
        Builds the prompt for schedule generation based on type,
        now including logic for the LLM to understand times for daily schedules.
        """
        if schedule_type == "day":
            return f"""
You are an expert productivity assistant. The user needs help organizing their daily tasks into a structured schedule.

User's consolidated tasks, wake-up time, and sleep time are provided below.
**VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
1.  **Identify the user's wake-up time and sleep time from the "User's Input".** Be flexible in understanding natural language (e.g., "6 pm in morning" should be 6:00 AM, "11 pm" should be 11:00 PM, "midnight" is 12:00 AM, "7" means 7:00 AM).
2.  If wake-up time is not clearly stated, assume 7:00 AM.
3.  If sleep time is not clearly stated, assume 10:00 PM.
4.  **Crucially, the schedule MUST start at the detected/default wake-up time and the VERY LAST activity MUST conclude EXACTLY at the detected/default sleep time.** Do not extend past the sleep time.
5.  **Ensure logical time progression:** Each task's end time MUST be after its start time. The next task MUST start immediately after the previous one ends.

User's Input:
\"\"\"
{task_description}
\"\"\"

Please create a realistic day schedule that:
1. Incorporates all the user's tasks.
2. Includes appropriate breaks and buffer time.
3. Considers task priorities and logical ordering.
4. Accounts for meals and personal time.
5. Ensure lunch is scheduled between 12:30 PM and 2:00 PM.
6. Ensure dinner is scheduled between 8:00 PM and 10:00 PM.

Format your response EXACTLY like this (use a TAB between Time and Task). Start with the header and your first time slot should be the detected/default wake-up time.
🗓 Today's Schedule
Time\tTask
[Detected/Default Wake-up Time] - [Next Hour Example/Calculated End Time]\tMorning routine and breakfast
... continue logically until [Detected/Default Sleep Time] (This last time slot MUST end at the sleep time).

Strictly adhere to the single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule block.
Ensure every scheduled item has a clear start and end time.
"""
        elif schedule_type == "week":
            return f"""
You are an expert productivity assistant. The user needs help organizing their weekly tasks and goals into a structured 7-day schedule.

User's Tasks, Goals, and Requirements for the week are provided below.
**VERY IMPORTANT RULES FOR TIME MANAGEMENT AND FORMAT:**
1.  The schedule should cover 7 days, from Monday to Sunday.
2.  For each day, include a logical flow of activities.
3.  Ensure lunch is scheduled between 12:30 PM and 2:00 PM on all days.
4.  Ensure dinner is scheduled between 8:00 PM and 10:00 PM on all days.
5.  Assume typical wake-up (e.g., 8:00 AM) and sleep (e.g., 10:00 PM) times if not implied by specific tasks.

User's Weekly Input:
\"\"\"
{task_description}
\"\"\"

Please create a realistic weekly schedule that:
1. Distributes ALL user's tasks and goals across the week appropriately.
2. Balances work, personal time, and rest.
3. Considers task priorities and deadlines.
4. Includes time for meals, breaks, and self-care.
5. Accounts for weekday vs weekend differences.

Format your response EXACTLY like this (use a TAB between Time and Task):
📅 This Week's Schedule

MONDAY
Time\tTask
9:00-10:00 AM\tMorning routine
10:00-12:00 PM\tImportant task 1
...

TUESDAY
Time\tTask
9:00-10:00 AM\tMorning routine
...

Continue for all 7 days (Monday through Sunday).
Strictly adhere to this single schedule format. Do NOT provide alternative schedules or conversational text outside the schedule blocks for each day.
Ensure every scheduled item has a clear start and end time.
"""
        else:
            raise ValueError("Invalid schedule_type. Must be 'day' or 'week'.")

    def parse_and_format_schedule(self, raw_text: str, schedule_type: str) -> str:
        """
        Parses the raw AI text, extracts schedule blocks, and formats them consistently
        for both daily and weekly schedules.
        """
        lines = raw_text.strip().splitlines()
        formatted_output_lines = []
        current_day = None
        days_of_week_map = {
            'MONDAY': 'Monday', 'TUESDAY': 'Tuesday', 'WEDNESDAY': 'Wednesday', 'THURSDAY': 'Thursday',
            'FRIDAY': 'Friday', 'SATURDAY': 'Saturday', 'SUNDAY': 'Sunday'
        }

        # More flexible regex for time, but still relies on consistent separators or AM/PM
        time_task_regex = re.compile(r"^\s*([\d:.\s–-]+(?:AM|PM)?(?:\s*[-–]\s*[\d:.\s–-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)


        if schedule_type == "day":
            start_parsing = False
            for line in lines:
                stripped_line = line.strip()
                if "🗓 Today's Schedule" in stripped_line:
                    start_parsing = True
                    formatted_output_lines.append("🗓 Today's Schedule")
                    formatted_output_lines.append("=" * 60)
                    formatted_output_lines.append(f"{'Time'.ljust(20)} | {'Task'}")
                    formatted_output_lines.append("-" * 60)
                    continue

                if start_parsing:
                    if 'Time' in stripped_line and 'Task' in stripped_line or not stripped_line:
                        continue
                    match = time_task_regex.match(stripped_line)
                    if match:
                        time = match.group(1).strip()
                        task = match.group(2).strip()
                        formatted_output_lines.append(f"{time.ljust(20)} | {task}")
                    elif formatted_output_lines and not match and not stripped_line.startswith('...'):
                        break

        elif schedule_type == "week":
            formatted_output_lines.append("📅 This Week's Schedule")
            formatted_output_lines.append("=" * 80 + "\n")

            in_schedule_block = False
            for line in lines:
                stripped_line = line.strip()
                if not stripped_line:
                    continue

                is_day_header = False
                for day_keyword, display_day_name in days_of_week_map.items():
                    if day_keyword in stripped_line.upper() and ('TIME' not in stripped_line.upper() and 'TASK' not in stripped_line.upper()):
                        if in_schedule_block:
                            formatted_output_lines.append("\n")
                        formatted_output_lines.append(f"🗓 {display_day_name}")
                        formatted_output_lines.append("-" * 40)
                        current_day = display_day_name
                        in_schedule_block = True
                        is_day_header = True
                        break

                if is_day_header:
                    continue

                if in_schedule_block:
                    if 'Time' in stripped_line and 'Task' in stripped_line:
                        continue

                    match = time_task_regex.match(stripped_line)
                    if match:
                        time = match.group(1).strip()
                        task = match.group(2).strip()
                        formatted_output_lines.append(f"{time.ljust(15)} | {task}")
                    elif formatted_output_lines and not match and not stripped_line.startswith('...'):
                        in_schedule_block = False
        return "\n".join(formatted_output_lines)

    def run_scheduler(self, initial_prompt: str):
        """Main function to run the personal planner based on user input."""
        print("🧠 AI Personal Planner")
        print("=" * 60)

        schedule_type = self.classify_schedule_type(initial_prompt)
        print(f"Detected Schedule Type: {schedule_type.capitalize()}")

        task_description = initial_prompt # Default for weekly schedule

        if schedule_type == 'day':
            # For a daily schedule, get the detailed input including tasks and times
            daily_input_prompt = """
Please provide your daily tasks, wake-up time, and sleep time in one go.
Example: 'I need to finish my report, do laundry, and call mom. I wake up at 7:30 AM and sleep by 10:00 PM.'
Your input: """
            consolidated_daily_input = input(daily_input_prompt).strip()
            task_description = consolidated_daily_input # This is what the LLM will analyze for times and tasks

            print(f"\n⏳ Generating your daily schedule...")
            llm_prompt = self.build_schedule_prompt(task_description, schedule_type)
        else: # schedule_type is 'week'
            # For weekly schedule, prompt for consolidated tasks after classification
            weekly_input_prompt = """
Please provide your consolidated weekly tasks, goals, and any specific requirements in one go.
Example: 'This week, I need to complete project proposal, prepare for client meeting on Wednesday, go to gym Mon/Wed/Fri evenings, and relax on Sunday. My general wake-up is 8 AM and sleep is 10 PM.'
Your input: """
            consolidated_weekly_input = input(weekly_input_prompt).strip()
            task_description = consolidated_weekly_input

            print(f"\n⏳ Generating your weekly schedule...")
            llm_prompt = self.build_schedule_prompt(task_description, schedule_type)

        raw_llm_result = self._query_groq(llm_prompt)

        # --- Extracting wake/sleep times from the GENERATED SCHEDULE for display (Daily Only) ---
        wake_up_time_display = "N/A (Weekly Schedule)"
        sleep_time_display = "N/A (Weekly Schedule)"

        if schedule_type == 'day':
            schedule_lines = raw_llm_result.strip().splitlines()
            time_task_regex_for_display = re.compile(r"^\s*([\d:.\s–-]+(?:AM|PM)?(?:\s*[-–]\s*[\d:.\s–-]+(?:AM|PM)?)?)\s+([^\s].*)", re.IGNORECASE)

            parsed_times_tasks = []
            for line in schedule_lines:
                match = time_task_regex_for_display.match(line.strip())
                if match:
                    parsed_times_tasks.append(match.group(1).strip())

            if parsed_times_tasks:
                wake_up_time_display = parsed_times_tasks[0].split('-')[0].strip()
                last_time_slot_raw = parsed_times_tasks[-1]
                sleep_time_match = re.search(r'[-–]\s*([\d:.\s–-]+(?:AM|PM)?)', last_time_slot_raw, re.IGNORECASE)
                if sleep_time_match:
                    sleep_time_display = sleep_time_match.group(1).strip()
                else:
                    sleep_time_display = last_time_slot_raw.split('-')[0].strip()

        print(f"Schedule generated from approximately: {wake_up_time_display} to {sleep_time_display}")
        # --- End of display time extraction ---

        formatted_schedule = self.parse_and_format_schedule(raw_llm_result, schedule_type)

        print("\n" + formatted_schedule)

# scheduler_bot=Scheduler("gsk_UZDP84pXeRVOcvKlnGPiU2c5uqS")
# scheduler_bot.main("i want to make a schedule for today , i have to go to gym for 2hours , study for 3 hours")

import re
from datetime import datetime

import os
import requests

class RouterAgent:
    def __init__(self, groq_api_key=None, model="llama-3.1-8b-instant"):
        self.api_key = groq_api_key or os.getenv("gsk_UZDP8cvKlnGPiU2c5uqS")
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = model

    async def classify_prompt(self, user_prompt: str) -> str:
        """Use Groq LLM to classify the type of user query."""
        system_prompt = (
            "You are an intelligent routing assistant. Classify the user's prompt into exactly one of these categories:\n"
            "1. questionpaper - If the user wants to generate questions, solutions, or answer a paper.\n"
            "2. scheduler - If the user is asking to generate a study plan, schedule, or planner.\n"
            "3. query - If the user is asking about a specific course, topics, syllabus, or other academic details.\n"
            "Return only one of these values: questionpaper, scheduler, or query. Do not explain."
        )

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.2,
            "max_tokens": 10
        }

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        # response = requests.post(self.api_url, headers=headers, json=payload,timeout=20)
        try:
          async with httpx.AsyncClient() as client:
              response = await client.post("https://api.groq.com/openai/v1/chat/completions",headers=headers, json=payload, timeout=20)
          response.raise_for_status()
          data =  response.json()
          classification = data["choices"][0]["message"]["content"].strip().lower()
          return classification
        except httpx.HTTPStatusError as e:
            raise Exception(f"API request failed: {str(e)}")
        except Exception as e:
            raise Exception(f"Error classifying prompt: {str(e)}")

    async def route(self, user_prompt: str ,file=None):
        query_type = await self.classify_prompt(user_prompt)

        if query_type == "questionpaper":
            print("question paper call")
            return await self.call_questionpaper_bot(user_prompt , file=file)
        elif query_type == "scheduler":
            print("scheduler bot call")
            return await self.call_scheduler_bot(user_prompt)
        elif query_type == "query":
            print("query bot call")
            return await self.call_query_bot(user_prompt)
        else:
            return "❌ Unable to classify the query. Please try rephrasing."

    async def classify_question_answer(self, prompt , file=None):
          GROQ_API_URL="https://api.groq.com/openai/v1/chat/completions"

          headers = {"Authorization": f"Bearer {self.api_key}"}
          classification_prompt = f"""
                  You are a classification agent that determines whether a user wants to generate answers to a question paper or to generate a similar question paper.
                  Here are the rules:
                  -If the prompt mentions solving, answering, or providing answers to questions, then it's "answer".
                  -If the prompt mentions creating, generating, or making a similar/new paper based on the input, then it's "generate".
                  -Be strict and choose only one: "answer" or "generate".

          Prompt:
          {prompt.strip()}
          Answer:
          """

          payload = {
              "model": self.model,
              "messages": [
                  {"role": "user", "content": classification_prompt}
              ],
              "temperature": 0.2,
              "max_tokens": 10
          }

          # response = requests.post("https://api.groq.com/openai/v1/chat/completions", headers=headers, json=payload, timeout=20)
          # response.raise_for_status()
          try:
            async with httpx.AsyncClient() as client:
                response = await client.post(self.api_url, headers=headers, json=payload, timeout=20)
                response.raise_for_status()
                data =  response.json()
                result = data["choices"][0]["message"]["content"].strip().lower()
                return "answer" if "answer" in result else "question"
          except httpx.HTTPStatusError as e:
              raise Exception(f"API request failed: {str(e)}")
          except Exception as e:
              raise Exception(f"Error classifying question type: {str(e)}")

    async def call_questionpaper_bot(self,prompt,file=None):
      try:
            print("Classifying prompt")
            question_type = await self.classify_question_answer(prompt, file)
            print("Checkpoint1")
            questionP_bot = QuestionPaperBot(groq_api_key=self.api_key)
            print("Checkpoint2")
            if question_type == "answer":
                print("Solution Generator")
                result = await questionP_bot.generate_answer_paper(file)
                print("checkpoint 3")  # Ensure this is async
            else:
                print("Paper Generator")
                result = await questionP_bot.generate_question_paper(file)
                print("Checkpoint 3")  # Ensure this is async
            return result
      except Exception as e:
            return {"error": f"Failed to process question paper: {str(e)}"}
    async def call_scheduler_bot(self, prompt):
        """scheduler bot wala part me do functions hai , ek weekly basis scheduler karne wali
        aur ek daily ki schedule karne wali , so we will take the user prompt and see ki wo kiss type  ka
        schedule banana chah rha 1day or 1 week and call the fucntuons on that basis"""
        try:
            scheduler_bot = Scheduler(groq_api_key=self.api_key)
            result = await scheduler_bot.main(prompt)
            return result
        except Exception as e:
            return {"error": f"Failed to generate schedule: {str(e)}"}

    async def call_query_bot(self, prompt: str):
        try:
            print("query bot section")
            query_bot = QueryBot()  # Pass API key if needed
            chunks, metadata = query_bot.load_course_chunks()  # Assume sync for now
            index, model, _ = query_bot.build_faiss_index(chunks)  # Assume sync
            relevant_chunks = query_bot.retrieve_relevant_chunks(prompt, index, model, chunks, metadata)  # Assume sync
            print("🤖 Thinking...")
            answer = await query_bot.query_llama(prompt, relevant_chunks)  # Make this async if it involves I/O
            return answer
        except Exception as e:
            return {"error": f"Failed to process query: {str(e)}"}

from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional
from fastapi.responses import JSONResponse, StreamingResponse

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Or set specific origins like ["http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

router_agent = RouterAgent("gsk_UZDP83qNXeRVOcvKlnGPiU2c5uqS")
#groq api wagera ham code ke andar hi fix kardenge (init ke time i mean)
@app.post("/route")
async def route_handler(
    prompt: str = Form(...),
    file: Optional[UploadFile] = File(None)
):
    result = await router_agent.route(prompt, file)

    # result must be a dict like {"text": ..., "pdf_file": ...}
    text = result.get("text", "")
    pdf_file = result.get("pdf_file", None)

    # Only PDF
    if pdf_file and not text:
        return StreamingResponse(
            pdf_file,
            media_type="application/pdf",
            headers={"Content-Disposition": "attachment; filename=question_paper.pdf"}
        )

    # Only Text
    if text and not pdf_file:
        return JSONResponse(content={"text": text})

    # Text + PDF
    if text and pdf_file:
        return StreamingResponse(
            pdf_file,
            media_type="application/pdf",
            headers={
                "Content-Disposition": "attachment; filename=question_paper.pdf",
                "X-Question-Text": text  # optional header if needed
            }
        )

    # Fallback
    return JSONResponse(content={"message": "No output generated."})

import uvicorn
from pyngrok import ngrok
import nest_asyncio
!ngrok authtoken 2xNBjsJZXAxK_3YEAxPqFauzLBSHA8EJvn
# Allow async in Colab
nest_asyncio.apply()

# Start ngrok tunnel
public_url = ngrok.connect(8000)
print("Public URL:", public_url)

# Run FastAPI server
uvicorn.run(app, host="0.0.0.0", port=8000)

router=RouterAgent("gsk_UZDP83qNdETfsneAsaoqcvKlnGPiU2c5uqS")
prompt=input("Prompt")
file_path="/content/Eco_Paper.pdf"
router.route(prompt ,file_path)

